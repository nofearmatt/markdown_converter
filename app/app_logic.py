# -*- coding: utf-8 -*-
"""
–ú–æ–¥—É–ª—å –ª–æ–≥–∏–∫–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Ñ–∞–π–ª–æ–≤ AI Studio.
–û—Ç–≤–µ—á–∞–µ—Ç –∑–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–ø–æ–∫, –æ–±—Ä–∞–±–æ—Ç–∫—É JSON —Ñ–∞–π–ª–æ–≤ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é –≤ —Ñ–æ—Ä–º–∞—Ç .md
"""

import json
import os
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List

def ensure_destination_directory(dest_dir: str) -> bool:
    """
    –°–æ–∑–¥–∞–µ—Ç –ø–∞–ø–∫—É –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.
    
    Args:
        dest_dir: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è
        
    Returns:
        bool: True –µ—Å–ª–∏ –ø–∞–ø–∫–∞ —Å–æ–∑–¥–∞–Ω–∞ –∏–ª–∏ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, False –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
    """
    try:
        os.makedirs(dest_dir, exist_ok=True)
        return True
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø–∞–ø–∫–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è {dest_dir}: {e}")
        return False

def ensure_json_extension_for_extensionless_files(root_dir: str) -> int:
    """
    –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –¥–æ–±–∞–≤–ª—è–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ .json –≤—Å–µ–º —Ñ–∞–π–ª–∞–º –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –≤ –ø–∞–ø–∫–µ.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤. –ü—Ä–∏ –∫–æ–ª–ª–∏–∑–∏–∏ –¥–æ–±–∞–≤–ª—è–µ—Ç —Å—É—Ñ—Ñ–∏–∫—Å _jsonN.
    """
    renamed_count = 0
    for dirpath, _, filenames in os.walk(root_dir):
        for name in filenames:
            base, ext = os.path.splitext(name)
            if ext:
                continue
            src_path = os.path.join(dirpath, name)
            candidate = f"{name}.json"
            dst_path = os.path.join(dirpath, candidate)
            if os.path.exists(dst_path):
                i = 1
                while True:
                    alt = os.path.join(dirpath, f"{name}_json{i}.json")
                    if not os.path.exists(alt):
                        dst_path = alt
                        break
                    i += 1
            try:
                os.rename(src_path, dst_path)
                renamed_count += 1
            except Exception:
                continue
    return renamed_count

def validate_settings(settings: Dict[str, Any]) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏.
    
    Args:
        settings: –°–ª–æ–≤–∞—Ä—å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        
    Returns:
        bool: True –µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
    """
    required_keys = ['source_dir', 'dest_dir']
    for key in required_keys:
        if key not in settings:
            logging.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä: {key}")
            return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–π –ø–∞–ø–∫–∏
    if not os.path.exists(settings['source_dir']):
        logging.error(f"–ò—Å—Ö–æ–¥–Ω–∞—è –ø–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {settings['source_dir']}")
        return False
    
    return True

def log_conversion_process(source_dir: str, dest_dir: str, settings: Dict[str, Any]) -> None:
    """
    –õ–æ–≥–∏—Ä—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ—Ü–µ—Å—Å–µ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏.
    
    Args:
        source_dir: –ò—Å—Ö–æ–¥–Ω–∞—è –ø–∞–ø–∫–∞
        dest_dir: –ü–∞–ø–∫–∞ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è
        settings: –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
    """
    logging.info("=" * 60)
    logging.info("–ù–ê–ß–ê–õ–û –ö–û–ù–í–ï–†–¢–ê–¶–ò–ò AI STUDIO –í MARKDOWN")
    logging.info("=" * 60)
    logging.info(f"–ò—Å—Ö–æ–¥–Ω–∞—è –ø–∞–ø–∫–∞: {source_dir}")
    logging.info(f"–ü–∞–ø–∫–∞ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è: {dest_dir}")
    logging.info(f"–ù–∞—Å—Ç—Ä–æ–π–∫–∏: {json.dumps(settings, indent=2, ensure_ascii=False)}")
    logging.info("=" * 60)

def extract_markdown_content(data: Dict[str, Any], settings: Dict[str, Any]) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–ª—è Markdown –∏–∑ JSON –¥–∞–Ω–Ω—ã—Ö —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º.
    –†–µ–∞–ª–∏–∑—É–µ—Ç ¬´–±–æ–≥–∞—Ç—ã–π¬ª —Å—Ç–∏–ª—å –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è —Å —Å–µ–∫—Ü–∏—è–º–∏: –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ, system prompt,
    run settings –∏ –∫—Ä–∞—Å–∏–≤–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è.
    """

    def get_nested(obj: Dict[str, Any], path: str, default=None):
        current = obj
        for part in path.split('.'):
            if isinstance(current, dict) and part in current:
                current = current[part]
            else:
                return default
        return current

    def first_of(paths: List[str], default=None):
        for p in paths:
            val = get_nested(data, p, None)
            if val is not None:
                return val
        return default

    def coalesce_title() -> str:
        candidates = [
            get_nested(data, 'conversation.title'),
            data.get('conversationTitle'),
            get_nested(data, 'chat.title'),
            get_nested(data, 'thread.title'),
            get_nested(data, 'session.title'),
            get_nested(data, 'metadata.title'),
            data.get('title'),
            data.get('documentTitle'),
            data.get('name'),
        ]
        for t in candidates:
            if isinstance(t, str) and t.strip():
                return t.strip()
        # –§–æ–ª–±—ç–∫: –∏–º—è –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
        fallback = settings.get('__source_basename')
        if isinstance(fallback, str) and fallback.strip():
            return fallback.strip()
        return 'AI Studio –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è'

    def normalize_model(run_settings: Dict[str, Any]) -> str:
        if not isinstance(run_settings, dict):
            return ""
        model = run_settings.get('model') or run_settings.get('modelName') or ""
        return str(model)

    def format_run_settings(run_settings: Dict[str, Any]) -> List[str]:
        if not isinstance(run_settings, dict):
            return []
        lines = []
        # –ö–ª—é—á–µ–≤—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        if run_settings.get('temperature') is not None:
            lines.append(f"- temperature: {run_settings.get('temperature')}")
        if run_settings.get('topP') is not None or run_settings.get('topK') is not None:
            lines.append(f"- topP/topK: {run_settings.get('topP', '-')}/{run_settings.get('topK', '-')}")
        if run_settings.get('maxOutputTokens') is not None:
            lines.append(f"- maxOutputTokens: {run_settings.get('maxOutputTokens')}")

        # –§–ª–∞–≥–∏
        for flag in [
            'enableCodeExecution',
            'enableSearchAsATool',
            'enableBrowseAsATool',
            'enableAutoFunctionResponse'
        ]:
            if flag in run_settings:
                value = run_settings.get(flag)
                lines.append(f"- {flag}: {'‚úÖ' if value else '‚ùå'}")

        # Safety
        safety = run_settings.get('safetySettings')
        if isinstance(safety, list) and safety:
            # –ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞
            all_none = all(isinstance(s, dict) and s.get('threshold') == 'BLOCK_NONE' for s in safety)
            if all_none:
                lines.append("- safety: BLOCK_NONE (–≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏)")
            else:
                lines.append("- safety: custom")
        return lines

    def role_label(role: str) -> str:
        r = (role or '').lower()
        if r in ('assistant', 'model', 'ai'):
            return 'ü§ñ –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç'
        if r in ('user', 'human'):
            return 'üßë‚Äçüíª –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å'
        if r == 'system':
            return 'üõ†Ô∏è –°–∏—Å—Ç–µ–º–∞'
        return role.title() if role else '–°–æ–æ–±—â–µ–Ω–∏–µ'

    def _join_parts(parts_value) -> str:
        if isinstance(parts_value, list):
            chunks: List[str] = []
            for seg in parts_value:
                if isinstance(seg, dict):
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º—ã—Å–ª–∏ –≤ —á–∞—Å—Ç—è—Ö
                    if settings.get('exclude_thoughts', True) and seg.get('thought'):
                        continue
                    txt = seg.get('text')
                    if isinstance(txt, str) and txt:
                        chunks.append(txt)
                elif isinstance(seg, str):
                    chunks.append(seg)
            return "\n".join(chunks).strip()
        elif isinstance(parts_value, str):
            return parts_value
        return ''

    def collect_messages() -> List[Dict[str, Any]]:
        messages: List[Dict[str, Any]] = []
        # 1) –Ø–≤–Ω—ã–π –º–∞—Å—Å–∏–≤ messages
        explicit = data.get('messages')
        if isinstance(explicit, list):
            for item in explicit:
                if not isinstance(item, dict):
                    continue
                text = item.get('content') or item.get('text')
                if isinstance(text, list):
                    text = _join_parts(text)
                if not text:
                    continue
                messages.append({
                    'role': item.get('role'),
                    'content': text,
                    'timestamp': item.get('timestamp') or item.get('time')
                })

        # 2) chunkedPrompt.chunks
        if not messages:
            chunks = first_of(['chunkedPrompt.chunks'], [])
            if isinstance(chunks, list):
                for ch in chunks:
                    if not isinstance(ch, dict):
                        continue
                    if settings.get('exclude_thoughts', True) and ch.get('isThought'):
                        continue
                    text_val = ch.get('text') or _join_parts(ch.get('parts'))
                    if not text_val:
                        continue
                    messages.append({
                        'role': ch.get('role') or 'model',
                        'content': text_val,
                        'timestamp': ch.get('timestamp') or ch.get('time')
                    })

        return messages

    md_lines: List[str] = []

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    if settings.get('add_file_headers', True):
        md_lines.append(f"# üß† {coalesce_title()}\n")

    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏ run settings
    include_metadata = settings.get('include_metadata', True)
    run_settings = first_of(['run_settings', 'runSettings'], {}) or {}

    if include_metadata:
        md_lines.append('## üìã –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ')
        model_name = normalize_model(run_settings)
        if model_name:
            md_lines.append(f"- **–ú–æ–¥–µ–ª—å**: {model_name}")
        if run_settings.get('temperature') is not None:
            md_lines.append(f"- **–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞**: {run_settings.get('temperature')}")
        if run_settings.get('topP') is not None or run_settings.get('topK') is not None:
            md_lines.append(f"- **topP / topK**: {run_settings.get('topP', '-')}/{run_settings.get('topK', '-')}")
        if run_settings.get('maxOutputTokens') is not None:
            md_lines.append(f"- **–ú–∞–∫—Å. —Ç–æ–∫–µ–Ω–æ–≤**: {run_settings.get('maxOutputTokens')}")
        md_lines.append('')

    # System prompt (–µ—Å–ª–∏ –µ—Å—Ç—å –∏ –≤–∫–ª—é—á–µ–Ω–æ)
    if settings.get('include_system_prompt', True):
        sys_prompt = first_of(['system_prompt', 'systemInstruction.text'], None)
        if isinstance(sys_prompt, str) and sys_prompt.strip():
            md_lines.append('## üõ†Ô∏è System Prompt')
            md_lines.append('> ' + sys_prompt.replace('\n', '\n> '))
            md_lines.append('')

    # Run settings (–ø–æ–¥—Ä–æ–±–Ω—ã–µ —Ñ–ª–∞–≥–∏)
    if settings.get('include_run_settings', True) and isinstance(run_settings, dict) and run_settings:
        md_lines.append('## ‚öôÔ∏è Run Settings')
        md_lines.extend(format_run_settings(run_settings))
        md_lines.append('')

    # –°–æ–æ–±—â–µ–Ω–∏—è
    messages = collect_messages()
    if messages:
        for idx, msg in enumerate(messages, start=1):
            label = role_label(msg.get('role'))
            ts = msg.get('timestamp')
            if ts and settings.get('include_timestamps', True):
                md_lines.append(f"## [{ts}] {label}")
            else:
                md_lines.append(f"## {label}")
            md_lines.append(msg.get('content', ''))
            if idx < len(messages):
                md_lines.append('\n---\n')
        md_lines.append('')

    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ (—Ç–µ—Ö–Ω.)
    if settings.get('include_timestamps', True):
        md_lines.append('## ‚è∞ –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏')
        md_lines.append(f"- **–í—Ä–µ–º—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        md_lines.append('')
    
    # JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
    if settings.get('include_json_structure', False):
        md_lines.append('## üîç JSON –°—Ç—Ä—É–∫—Ç—É—Ä–∞')
        md_lines.append('```json')
        md_lines.append(json.dumps(data, indent=2, ensure_ascii=False))
        md_lines.append('```')
    
    return "\n".join(md_lines)

def convert_single_file(json_file_path: str, dest_dir: str, settings: Dict[str, Any]) -> bool:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –æ–¥–∏–Ω JSON —Ñ–∞–π–ª –≤ —Ñ–æ—Ä–º–∞—Ç Markdown.
    
    Args:
        json_file_path: –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É JSON —Ñ–∞–π–ª—É
        dest_dir: –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        settings: –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
        
    Returns:
        bool: True –µ—Å–ª–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
    """
    try:
        # –ß–∏—Ç–∞–µ–º JSON —Ñ–∞–π–ª
        with open(json_file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Ñ–æ–ª–±—ç–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞
        json_filename = os.path.basename(json_file_path)
        base_name = os.path.splitext(json_filename)[0]
        settings_with_fallback = dict(settings)
        settings_with_fallback['__source_basename'] = base_name

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º
        md_content = extract_markdown_content(data, settings_with_fallback)
        
        if not md_content:
            logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–∑ —Ñ–∞–π–ª–∞ {json_file_path}")
            return False
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        # json_filename –∏ base_name —É–∂–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã –≤—ã—à–µ
        md_filename = f"{base_name}.md"
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞–ø–∫—É –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è
        final_dest_dir = dest_dir
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–ø–∞–ø–∫–∏ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
        if settings.get("create_subfolders", True):
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –æ—Ç –∏—Å—Ö–æ–¥–Ω–æ–π –ø–∞–ø–∫–∏
            source_dir = settings.get("source_dir", "")
            if source_dir:
                rel_path = os.path.relpath(os.path.dirname(json_file_path), source_dir)
                if rel_path != ".":
                    final_dest_dir = os.path.join(dest_dir, rel_path)
                    # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–ø–∞–ø–∫—É –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                    os.makedirs(final_dest_dir, exist_ok=True)
        
        # –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
        output_path = os.path.join(final_dest_dir, md_filename)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        if os.path.exists(output_path) and not settings.get("overwrite_existing", False):
            # –ü—Ä–æ–ø—É—Å–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞ –Ω–µ —Å—á–∏—Ç–∞–µ—Ç—Å—è –æ—à–∏–±–∫–æ–π
            logging.warning(f"–§–∞–π–ª {output_path} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–µ–∑ –æ—à–∏–±–∫–∏.")
            return True
        
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        logging.info(f"–£—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω: {json_file_path} -> {output_path}")
        return True
        
    except json.JSONDecodeError as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –≤ —Ñ–∞–π–ª–µ {json_file_path}: {e}")
        return False
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞ {json_file_path}: {e}")
        return False

def convert_files(source_dir: str, dest_dir: str, settings: Dict[str, Any], progress_queue) -> None:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Ñ–∞–π–ª–æ–≤ AI Studio –≤ Markdown.
    
    Args:
        source_dir: –ü–∞–ø–∫–∞ —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ JSON —Ñ–∞–π–ª–∞–º–∏
        dest_dir: –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        settings: –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
        progress_queue: –û—á–µ—Ä–µ–¥—å –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –≤ GUI
    """
    try:
        # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞—á–∞–ª–æ –ø—Ä–æ—Ü–µ—Å—Å–∞
        log_conversion_process(source_dir, dest_dir, settings)
        
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        if not validate_settings(settings):
            progress_queue.put({
                "type": "error",
                "message": "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã source_dir –∏ dest_dir."
            })
            return
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ —Å–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è
        if not ensure_destination_directory(dest_dir):
            progress_queue.put({
                "type": "error",
                "message": f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø–∞–ø–∫—É –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è: {dest_dir}"
            })
            return
        
        # –°–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤–∏–º .json –∫–æ –≤—Å–µ–º —Ñ–∞–π–ª–∞–º –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
        try:
            renamed = ensure_json_extension_for_extensionless_files(source_dir)
            if renamed:
                logging.info(f"–ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–æ —Ñ–∞–π–ª–æ–≤ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è: {renamed}")
        except Exception:
            pass

        # –°–∫–∞–Ω–∏—Ä—É–µ–º –∏—Å—Ö–æ–¥–Ω—É—é –ø–∞–ø–∫—É: —Ç–æ–ª—å–∫–æ .json
        json_files: List[str] = []
        for root, dirs, files in os.walk(source_dir):
            for file in files:
                if file.lower().endswith('.json'):
                    json_files.append(os.path.join(root, file))
        
        if not json_files:
            progress_queue.put({
                "type": "info",
                "message": f"–í –ø–∞–ø–∫–µ {source_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö JSON-—Ñ–∞–π–ª–æ–≤"
            })
            return
        
        logging.info(f"–ù–∞–π–¥–µ–Ω–æ {len(json_files)} JSON —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏")
        progress_queue.put({
            "type": "info",
            "message": f"–ù–∞–π–¥–µ–Ω–æ {len(json_files)} JSON —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏"
        })
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
        successful_conversions = 0
        failed_conversions = 0
        
        for i, json_file in enumerate(json_files):
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            progress = int((i / len(json_files)) * 100)
            progress_queue.put({
                "type": "progress",
                "value": progress,
                "message": f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ñ–∞–π–ª–∞ {i+1} –∏–∑ {len(json_files)}: {os.path.basename(json_file)}"
            })
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª
            if convert_single_file(json_file, dest_dir, settings):
                successful_conversions += 1
            else:
                failed_conversions += 1
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å
        progress_queue.put({
            "type": "progress",
            "value": 100,
            "message": "–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞"
        })
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        logging.info(f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –£—Å–ø–µ—à–Ω–æ: {successful_conversions}, –û—à–∏–±–æ–∫: {failed_conversions}")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        if failed_conversions == 0:
            progress_queue.put({
                "type": "success",
                "message": f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {successful_conversions}"
            })
        else:
            progress_queue.put({
                "type": "warning",
                "message": f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏. –£—Å–ø–µ—à–Ω–æ: {successful_conversions}, –û—à–∏–±–æ–∫: {failed_conversions}"
            })
            
    except Exception as e:
        error_msg = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}"
        logging.error(error_msg)
        progress_queue.put({
            "type": "error",
            "message": error_msg
        })
